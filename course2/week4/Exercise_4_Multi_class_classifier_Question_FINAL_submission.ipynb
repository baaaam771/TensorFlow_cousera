{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_4_Multi_class_classifier_Question-FINAL_submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUg0VEAs8dRV"
      },
      "source": [
        "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\r\n",
        "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\r\n",
        "# ATTENTION: Please use the provided epoch values when training.\r\n",
        "\r\n",
        "import csv\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from os import getcwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M9AUEak8pjJ"
      },
      "source": [
        "def get_data(filename):\r\n",
        "  # You will need to write code that will read the file passed\r\n",
        "  # into this function. The first line contains the column headers\r\n",
        "  # so you should ignore it\r\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\r\n",
        "  # The first value is the label\r\n",
        "  # The rest are the pixel values for that picture\r\n",
        "  # The function will return 2 np.array types. One with all the labels\r\n",
        "  # One with all the images\r\n",
        "  #\r\n",
        "  # Tips: \r\n",
        "  # If you read a full line (as 'row') then row[0] has the label\r\n",
        "  # and row[1:785] has the 784 pixel values\r\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\r\n",
        "  # You are reading in strings, but need the values to be floats\r\n",
        "  # Check out np.array().astype for a conversion\r\n",
        "    with open(filename) as training_file:\r\n",
        "        read=csv.reader(training_file,delimiter=',')\r\n",
        "        first_line=True\r\n",
        "        temp_images=[]\r\n",
        "        temp_labels=[]\r\n",
        "        for row in read:\r\n",
        "            if first_line:\r\n",
        "                first_line=False\r\n",
        "            else:\r\n",
        "                temp_labels.append(row[0])\r\n",
        "                images_data=row[1:785]\r\n",
        "                as_array=np.array_split(images_data,28)\r\n",
        "                temp_images.append(as_array)\r\n",
        "        \r\n",
        "        images=np.array(temp_images).astype('float')\r\n",
        "        labels=np.array(temp_labels).astype('float')\r\n",
        "    return images, labels\r\n",
        "\r\n",
        "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\r\n",
        "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\r\n",
        "training_images, training_labels = get_data(path_sign_mnist_train)\r\n",
        "testing_images, testing_labels = get_data(path_sign_mnist_test)\r\n",
        "\r\n",
        "# Keep these\r\n",
        "print(training_images.shape)\r\n",
        "print(training_labels.shape)\r\n",
        "print(testing_images.shape)\r\n",
        "print(testing_labels.shape)\r\n",
        "\r\n",
        "# Their output should be:\r\n",
        "# (27455, 28, 28)\r\n",
        "# (27455,)\r\n",
        "# (7172, 28, 28)\r\n",
        "# (7172,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqNTZEyO8tE8"
      },
      "source": [
        "# In this section you will have to add another dimension to the data\r\n",
        "# So, for example, if your array is (10000, 28, 28)\r\n",
        "# You will need to make it (10000, 28, 28, 1)\r\n",
        "# Hint: np.expand_dims\r\n",
        "\r\n",
        "training_images = np.expand_dims(training_images, axis=-1)\r\n",
        "testing_images = np.expand_dims(testing_images, axis=-1)\r\n",
        "\r\n",
        "# Create an ImageDataGenerator and do Image Augmentation\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "      rescale = 1./255,\r\n",
        "\t  rotation_range=40,\r\n",
        "      width_shift_range=0.2,\r\n",
        "      height_shift_range=0.2,\r\n",
        "      shear_range=0.2,\r\n",
        "      zoom_range=0.2,\r\n",
        "      horizontal_flip=True,\r\n",
        "      fill_mode='nearest'\r\n",
        "    )\r\n",
        "\r\n",
        "validation_datagen = ImageDataGenerator(\r\n",
        "    rescale = 1./255)\r\n",
        "    \r\n",
        "# Keep These\r\n",
        "print(training_images.shape)\r\n",
        "print(testing_images.shape)\r\n",
        "    \r\n",
        "# Their output should be:\r\n",
        "# (27455, 28, 28, 1)\r\n",
        "# (7172, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auSFvYGn8wJG"
      },
      "source": [
        "# Define the model\r\n",
        "# Use no more than 2 Conv2D and 2 MaxPooling2D\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\r\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "    # The second convolution\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    # Flatten the results to feed into a DNN\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    # 512 neuron hidden layer\r\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "# Compile Model. \r\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\r\n",
        "\r\n",
        "# Train the Model\r\n",
        "history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size=32),\r\n",
        "                              steps_per_epoch=len(training_images) / 32,\r\n",
        "                              epochs=2,\r\n",
        "                              validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),\r\n",
        "                              validation_steps=len(testing_images) / 32)\r\n",
        "\r\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLNnIcHo80cT"
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G374iccn82am"
      },
      "source": [
        "%%javascript\r\n",
        "<!-- Save the notebook -->\r\n",
        "IPython.notebook.save_checkpoint();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjBJVVFG84fd"
      },
      "source": [
        "%%javascript\r\n",
        "IPython.notebook.session.delete();\r\n",
        "window.onbeforeunload = null\r\n",
        "setTimeout(function() { window.close(); }, 1000);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}