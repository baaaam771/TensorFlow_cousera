{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL_submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CALEuI7iyUX7"
      },
      "source": [
        "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\r\n",
        "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\r\n",
        "# ATTENTION: Please use the provided epoch values when training.\r\n",
        "\r\n",
        "# Import all the necessary files!\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import Model\r\n",
        "from os import getcwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFm-IOsycZP"
      },
      "source": [
        "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\r\n",
        "\r\n",
        "# Import the inception model  \r\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n",
        "\r\n",
        "# Create an instance of the inception model from the local pre-trained weights\r\n",
        "local_weights_file = path_inception\r\n",
        "\r\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \r\n",
        "                                include_top = False, \r\n",
        "                                weights = None)\r\n",
        "\r\n",
        "pre_trained_model.load_weights(local_weights_file)\r\n",
        "\r\n",
        "# Make all the layers in the pre-trained model non-trainable\r\n",
        "for layer in pre_trained_model.layers:\r\n",
        "  layer.trainable = False\r\n",
        "  \r\n",
        "# Print the model summary\r\n",
        "pre_trained_model.summary()\r\n",
        "\r\n",
        "# Expected Output is extremely large, but should end with:\r\n",
        "\r\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \r\n",
        "#__________________________________________________________________________________________________\r\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \r\n",
        "#__________________________________________________________________________________________________\r\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \r\n",
        "#                                                                 activation_276[0][0]             \r\n",
        "#__________________________________________________________________________________________________\r\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \r\n",
        "#                                                                 activation_280[0][0]             \r\n",
        "#__________________________________________________________________________________________________\r\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \r\n",
        "#__________________________________________________________________________________________________\r\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \r\n",
        "#                                                                 mixed9_1[0][0]                   \r\n",
        "#                                                                 concatenate_5[0][0]              \r\n",
        "#                                                                 activation_281[0][0]             \r\n",
        "#==================================================================================================\r\n",
        "#Total params: 21,802,784\r\n",
        "#Trainable params: 0\r\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fFpqukDyeGq"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\r\n",
        "print('last layer output shape: ', last_layer.output_shape)\r\n",
        "last_output = last_layer.output\r\n",
        "\r\n",
        "# Expected Output:\r\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7icvkeryhXj"
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 97.0%\r\n",
        "class myCallback(tf.keras.callbacks.Callback):\r\n",
        "  def on_epoch_end(self, epoch, logs={}):\r\n",
        "    if(logs.get('acc')>0.97):\r\n",
        "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdvtbEe5yipJ"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "# Flatten the output layer to 1 dimension\r\n",
        "x = layers.Flatten()(last_output)\r\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\r\n",
        "x = layers.Dense(1024, activation='relu')(x)\r\n",
        "# Add a dropout rate of 0.2\r\n",
        "x = layers.Dropout(0.2)(x)                  \r\n",
        "# Add a final sigmoid layer for classification\r\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \r\n",
        "\r\n",
        "model = Model( pre_trained_model.input, x) \r\n",
        "\r\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \r\n",
        "              loss = 'binary_crossentropy', \r\n",
        "              metrics = ['acc'])\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Expected output will be large. Last few lines should be:\r\n",
        "\r\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \r\n",
        "#                                                                  activation_251[0][0]             \r\n",
        "#                                                                  activation_256[0][0]             \r\n",
        "#                                                                  activation_257[0][0]             \r\n",
        "# __________________________________________________________________________________________________\r\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \r\n",
        "# __________________________________________________________________________________________________\r\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \r\n",
        "# __________________________________________________________________________________________________\r\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \r\n",
        "# __________________________________________________________________________________________________\r\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \r\n",
        "# ==================================================================================================\r\n",
        "# Total params: 47,512,481\r\n",
        "# Trainable params: 38,537,217\r\n",
        "# Non-trainable params: 8,975,264\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPIW9616ykcS"
      },
      "source": [
        "# Get the Horse or Human dataset\r\n",
        "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\r\n",
        "# Get the Horse or Human Validation dataset\r\n",
        "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "import os\r\n",
        "import zipfile\r\n",
        "import shutil\r\n",
        "\r\n",
        "shutil.rmtree('/tmp')\r\n",
        "local_zip = path_horse_or_human\r\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('/tmp/training')\r\n",
        "zip_ref.close()\r\n",
        "\r\n",
        "local_zip = path_validation_horse_or_human\r\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "zip_ref.extractall('/tmp/validation')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyyHp8SDynQP"
      },
      "source": [
        "# Define our example directories and files\r\n",
        "train_dir = '/tmp/training'\r\n",
        "validation_dir = '/tmp/validation'\r\n",
        "\r\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')\r\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\r\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\r\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\r\n",
        "\r\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\r\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\r\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\r\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\r\n",
        "\r\n",
        "print(len(train_horses_fnames))\r\n",
        "print(len(train_humans_fnames))\r\n",
        "print(len(validation_horses_fnames))\r\n",
        "print(len(validation_humans_fnames))\r\n",
        "\r\n",
        "# Expected Output:\r\n",
        "# 500\r\n",
        "# 527\r\n",
        "# 128\r\n",
        "# 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMurBR5jyo09"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\r\n",
        "                                   rotation_range = 40,\r\n",
        "                                   width_shift_range = 0.2,\r\n",
        "                                   height_shift_range = 0.2,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "# Note that the validation data should not be augmented!\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255. )\r\n",
        "\r\n",
        "# Flow training images in batches of 20 using train_datagen generator\r\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\r\n",
        "                                                    batch_size = 20,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    target_size = (150, 150))     \r\n",
        "\r\n",
        "# Flow validation images in batches of 20 using test_datagen generator\r\n",
        "validation_generator =  test_datagen.flow_from_directory(  validation_dir,\r\n",
        "                                                          batch_size  = 20,\r\n",
        "                                                          class_mode  = 'binary', \r\n",
        "                                                          target_size = (150, 150))\r\n",
        "\r\n",
        "# Expected Output:\r\n",
        "# Found 1027 images belonging to 2 classes.\r\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtA3jjxOyqkB"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\r\n",
        "# fires, and stops training at 97% accuracy\r\n",
        "\r\n",
        "callbacks = myCallback()\r\n",
        "history = model.fit_generator(train_generator,\r\n",
        "            validation_data = validation_generator,\r\n",
        "            steps_per_epoch = 100,\r\n",
        "            epochs = 3,\r\n",
        "            validation_steps = 50,\r\n",
        "            verbose = 1,\r\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zykHKhazys6F"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend(loc=0)\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCKGr1jyvV5"
      },
      "source": [
        "%%javascript\r\n",
        "<!-- Save the notebook -->\r\n",
        "IPython.notebook.save_checkpoint();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ROM5O-Gyv8V"
      },
      "source": [
        "%%javascript\r\n",
        "IPython.notebook.session.delete();\r\n",
        "window.onbeforeunload = null\r\n",
        "setTimeout(function() { window.close(); }, 1000);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}